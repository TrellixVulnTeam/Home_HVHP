{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1tfk5ys1u9x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.layers import TextVectorization\n",
        "from keras.layers import Embedding\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "metadata": {
        "id": "NsxcbgFB1rwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing Data"
      ],
      "metadata": {
        "id": "eEt7GQfTqlWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read csv in as df\n",
        "df = pd.read_csv('/content/drive/MyDrive/GitHub/Home/Financial/Data/pos_expenses_data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "v6ocnd5T4EgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define data types for columns\n",
        "new_df_schema = {\n",
        "'Location': df['Location'].astype(str),\n",
        "'Description': df['Description'].astype(str),\n",
        "'Cost': pd.to_numeric(df['Cost'], errors='coerce'),\n",
        "'Category': df['Category'].astype(str),\n",
        "'Day': df['Day'].astype(str),\n",
        "'Month': df['Month'].astype(str),\n",
        "'Year': df['Year'].astype(str),\n",
        "}\n",
        "\n",
        "# update the data types\n",
        "df = pd.DataFrame(new_df_schema)"
      ],
      "metadata": {
        "id": "nQFe7LiUB2-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "yVaAHXBcqgcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "c9w18uOFqroj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = df.drop('Category', axis=1)\n",
        "labels = df['Category']"
      ],
      "metadata": {
        "id": "NDDtJumDqUjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = pd.unique(labels)\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Number of samples:\", len(features))"
      ],
      "metadata": {
        "id": "fydecWFBtsIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "descriptions = df['Description']"
      ],
      "metadata": {
        "id": "G9ruh82N6REK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.get_dummies(labels)"
      ],
      "metadata": {
        "id": "tQL0GxvyHZjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples, test_samples, train_labels, test_labels = train_test_split(descriptions, labels, test_size=0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "eybAr_JH6iND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Vocabulary Index"
      ],
      "metadata": {
        "id": "keGlpnmC9zLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
        "vectorizer.adapt(text_ds)"
      ],
      "metadata": {
        "id": "whip5oJy8DPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_vocabulary()[:10]"
      ],
      "metadata": {
        "id": "HZPrRj9u8hX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "metadata": {
        "id": "TkZ43YQJ9SBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load pre-trained GloVe"
      ],
      "metadata": {
        "id": "gkMYzNUD-B8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "RRNuuHd99Yfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_glove_file = os.path.join(\n",
        "    os.path.expanduser(\"~\"), \"/content/glove.6B.100d.txt\"\n",
        ")\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "metadata": {
        "id": "_XB1ttlq9b3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = len(voc) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "metadata": {
        "id": "d2pm1pXG9wML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ],
      "metadata": {
        "id": "v45Zu3mi-S6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded_sequences = embedding_layer(int_sequences_input)\n",
        "print(int_sequences_input)"
      ],
      "metadata": {
        "id": "o3dpuJ0NFUJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "m0FtNlV8Av0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded_sequences = embedding_layer(int_sequences_input)\n",
        "\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
        "model = keras.Model(int_sequences_input, preds)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "rEPbxNU_AVjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "C7HjMKXOAyBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
        "x_test = vectorizer(np.array([[s] for s in test_samples])).numpy()\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)"
      ],
      "metadata": {
        "id": "j43zxR4_AzS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
        ")\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "PECmV6ksA7PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "_JbrC22D3qLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "xFrn0td1I0bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(x_test) \n",
        "pred = np.argmax(pred, axis = 1)[:5] \n",
        "label = np.argmax(y_test,axis = 1)[:5] \n",
        "\n",
        "print(pred) \n",
        "print(label)"
      ],
      "metadata": {
        "id": "kHuo4EHOKVmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display Results"
      ],
      "metadata": {
        "id": "J8H4utk13u5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(x_test)\n",
        "pred_df = pd.DataFrame(pred, columns = ['alcohol', 'business',\t'clothes',\t'education',\t'entertainment',\t'grocery',\t'health', 'hygiene', 'improvement',\t'misc',\t'rent',\t'restaurant',\t'supplies',\t'transportation',\t'utilities'])\n",
        "pred_df = pred_df.idxmax(axis=1)[:50]\n",
        "\n",
        "label_df = pd.DataFrame(y_test, columns = ['alcohol', 'business',\t'clothes',\t'education',\t'entertainment',\t'grocery',\t'health',\t'hygiene', 'improvement',\t'misc',\t'rent',\t'restaurant',\t'supplies',\t'transportation',\t'utilities'])\n",
        "label_df = label_df.idxmax(axis=1)[:50]\n",
        "\n",
        "test_df = test_samples.reset_index(drop=True)[:50]\n",
        "compare_df = pd.concat([test_df, pred_df, label_df], axis=1)\n",
        "compare_df.columns =['Description', 'Predicted', 'Actual']\n",
        "\n",
        "compare_df"
      ],
      "metadata": {
        "id": "l4keow2cNIzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classify text input"
      ],
      "metadata": {
        "id": "apij158i32Nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorizer(string_input)\n",
        "preds = model(x)\n",
        "end_to_end_model = keras.Model(string_input, preds)\n",
        "\n",
        "probabilities = end_to_end_model.predict(\n",
        "    [[\"bagels\"]]\n",
        ")\n",
        "\n",
        "class_names[np.argmax(probabilities[0])]"
      ],
      "metadata": {
        "id": "yVXBWaZHYYv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions:\n",
        "Which categories had the worst accuracy? The best?"
      ],
      "metadata": {
        "id": "fYG1Kx-h33WV"
      }
    }
  ]
}